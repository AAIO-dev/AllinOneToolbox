const express = require('express');
const axios = require('axios');
const router = express.Router();

// Ÿáÿ∞Ÿá ÿßŸÑÿØÿßŸÑÿ© ÿ™ÿ∫ŸÑŸÅ ŸÖÿ≥ÿ™ÿ¥ÿßÿ±ŸäŸÉ ŸÑÿ™ÿ≥ÿ™ŸÇÿ®ŸÑ ÿßŸÑÿ•ÿπÿØÿßÿØÿßÿ™ ŸÖŸÜ ÿßŸÑÿ≥Ÿäÿ±ŸÅÿ± ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä
module.exports = function(client, getRecentHistory, UNIFIED_PROMPT) {


// --- Gemini Advisor ---
router.post('/ask-gemini', async (req, res) => {
    // 1. ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßŸÑŸÄ sessionId ŸàÿßŸÑŸÄ prompt ŸÖŸÜ ÿßŸÑÿ∑ŸÑÿ® ÿßŸÑŸÇÿßÿØŸÖ
    const { prompt, sessionId } = req.body; 
    console.log(`üöÄ Gemini processing request for session: ${sessionId}`);

    try {
        // 2. ÿ™ŸÖÿ±Ÿäÿ± ÿßŸÑŸÄ sessionId ŸÑŸÑÿØÿßŸÑÿ© ŸÑÿ¨ŸÑÿ® ÿßŸÑÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿÆÿßÿµ ÿ®Ÿáÿ∞ÿß ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑
        const historyText = await getRecentHistory(sessionId);
        
        const finalPrompt = `
${UNIFIED_PROMPT}
---
Council History:
${historyText}
---
User Query: ${prompt}
Note: Respond in the same language as the User Query.
`;

        const response = await axios.post(
            `https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent?key=${process.env.GEMINI_API_KEY}`,
            {
                system_instruction: { parts: [{ text: UNIFIED_PROMPT }] },
                contents: [{ role: "user", parts: [{ text: finalPrompt }] }]
            }
        );

        const reply = response.data.candidates[0].content.parts[0].text;

        // 3. ÿ≠ŸÅÿ∏ ÿßŸÑŸÄ sessionId ŸÅŸä ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸÑÿ∂ŸÖÿßŸÜ ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±Ÿäÿ© ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©
        const database = client.db("AAIO-Memory");
        await database.collection("chat_history").insertOne({
            sessionId: sessionId, // ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑŸáŸàŸäÿ©
            advisor: "Gemini",
            userName: "User", 
            userPrompt: prompt,
            botReply: reply,
            timestamp: new Date()
        });

        res.json({ reply });
    } catch (error) {
        console.error("‚ùå Gemini Error:", error.response?.data || error.message);
        res.status(500).json({ error: "Gemini Service Unavailable" });
    }
});

// --- Perplexity Advisor ---
router.post('/ask-perplexity', async (req, res) => {
    // 1. ÿßÿ≥ÿ™ŸÑÿßŸÖ ÿßŸÑŸáŸàŸäÿ© ŸàÿßŸÑÿ≥ÿ§ÿßŸÑ
    const { prompt, sessionId } = req.body; 
    console.log(`üöÄ Perplexity processing for session: ${sessionId}`);

    try {
        // 2. ÿ¨ŸÑÿ® ÿ™ÿßÿ±ŸäÿÆ Ÿáÿ∞Ÿá ÿßŸÑÿ¨ŸÑÿ≥ÿ© ŸÅŸÇÿ∑
        const historyText = await getRecentHistory(sessionId);
        
        const finalPrompt = `
${UNIFIED_PROMPT}
---
Council History:
${historyText}
---
User Query: ${prompt}
Note: You MUST respond in the exact same language used in the User Query above. Ignore the language of the History if it differs.
`;

        const response = await axios.post('https://api.perplexity.ai/chat/completions', {
            model: "sonar",
            messages: [
                { role: "system", content: UNIFIED_PROMPT },
                { role: "user", content: finalPrompt }
            ]
        }, {
            headers: { 'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}` }
        });

        const reply = response.data.choices[0].message.content;

        // 3. ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑÿ±ÿØ ŸÖÿπ ÿ±ÿ®ÿ∑Ÿá ÿ®ÿßŸÑŸÄ sessionId
        const database = client.db("AAIO-Memory");
        await database.collection("chat_history").insertOne({
            sessionId: sessionId, 
            advisor: "Perplexity",
            userName: "User", // ÿ≠ÿßŸÅÿ∏ŸÜÿß ÿπŸÑŸâ ÿßŸÑÿÆÿµŸàÿµŸäÿ© ŸáŸÜÿß
            userPrompt: prompt,
            botReply: reply,
            timestamp: new Date()
        });

        res.json({ reply });
    } catch (error) {
        console.error("‚ùå Perplexity Error:", error.message);
        // ÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿÆÿ∑ÿ£ ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ© ŸÉŸÖÿß ÿßÿ™ŸÅŸÇŸÜÿß
        res.status(500).json({ error: "Perplexity Service Unavailable" });
    }
});

// --- ChatGPT Advisor ---
router.post('/ask-chatgpt', async (req, res) => {
    // 1. ÿßÿ≥ÿ™ŸÑÿßŸÖ ÿßŸÑŸáŸàŸäÿ© (sessionId) ŸàÿßŸÑÿ≥ÿ§ÿßŸÑ ŸÖŸÜ ÿßŸÑÿ∑ŸÑÿ®
    const { prompt, sessionId } = req.body;
    try {
        // 2. ÿ¨ŸÑÿ® ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ¨ŸÑÿ≥ÿ© ÿßŸÑÿÆÿßÿµ ÿ®Ÿáÿ∞ÿß ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑
        const historyText = await getRecentHistory(sessionId); 
        
        const finalPrompt = `
${UNIFIED_PROMPT}
---
Council History:
${historyText}
---
User Query: ${prompt}
Note: You MUST respond in the exact same language used in the User Query above.
`;

        const response = await axios.post('https://api.openai.com/v1/chat/completions', {
            model: "gpt-4o", // ÿ™ŸÖ ÿßŸÑÿ•ÿ®ŸÇÿßÿ° ÿπŸÑŸâ ÿßŸÑŸÖŸàÿØŸäŸÑ ÿßŸÑÿ£ŸÇŸàŸâ ŸÉŸÖÿß ŸáŸà ŸÅŸä ŸÉŸàÿØŸÉ
            messages: [
                { role: "system", content: UNIFIED_PROMPT },
                { role: "user", content: finalPrompt }
            ]
        }, {
            headers: { 'Authorization': `Bearer ${process.env.OPENAI_API_KEY}` }
        });

        const reply = response.data.choices[0].message.content;

        // 3. ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑÿ±ÿØ ŸÅŸä MongoDB ŸÖÿπ ÿ±ÿ®ÿ∑Ÿá ÿ®ÿßŸÑŸÄ sessionId
        await client.db("AAIO-Memory").collection("chat_history").insertOne({
            sessionId: sessionId, // ÿ•ÿ∂ÿßŸÅÿ© ÿ≠ŸÇŸÑ ÿßŸÑŸáŸàŸäÿ© ŸÑÿ∂ŸÖÿßŸÜ ÿπÿØŸÖ ÿ™ÿØÿßÿÆŸÑ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©
            advisor: "ChatGPT",
            userName: "User", 
            userPrompt: prompt,
            botReply: reply,
            timestamp: new Date()
        });

        res.json({ reply });
    } catch (error) {
        console.error("‚ùå ChatGPT Error:", error.message);
        res.status(500).json({ error: "ChatGPT Service Unavailable" });
    }
});

// --- DeepSeek Advisor ---
router.post('/ask-deepseek', async (req, res) => {
    // 1. ÿßÿ≥ÿ™ŸÑÿßŸÖ ÿßŸÑŸáŸàŸäÿ© ŸàÿßŸÑÿ≥ÿ§ÿßŸÑ
    const { prompt, sessionId } = req.body;
    try {
        // 2. ÿ¨ŸÑÿ® ÿßŸÑÿ™ÿßÿ±ŸäÿÆ ÿßŸÑŸÖŸÅŸÑÿ™ÿ± ŸÑŸÑÿ¨ŸÑÿ≥ÿ©
        const historyText = await getRecentHistory(sessionId);
        
        const finalPrompt = `
${UNIFIED_PROMPT}
---
Council History:
${historyText}
---
User Query: ${prompt}
Note: You MUST respond in the exact same language used in the User Query above.
`;

        const response = await axios.post('https://api.deepseek.com/chat/completions', {
            model: "deepseek-reasoner", // ÿßŸÑŸÖŸàÿØŸäŸÑ ÿßŸÑÿ∞Ÿä Ÿäÿ™ŸÖŸäÿ≤ ÿ®ÿßŸÑÿ™ŸÅŸÉŸäÿ± ÿßŸÑÿπŸÖŸäŸÇ
            messages: [
                { role: "system", content: UNIFIED_PROMPT },
                { role: "user", content: finalPrompt }
            ]
        }, {
            headers: { 'Authorization': `Bearer ${process.env.DEEPSEEK_API_KEY}` }
        });

        const reply = response.data.choices[0].message.content;

        // 3. ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑÿ±ÿØ ŸÖÿπ ÿ±ÿ®ÿ∑Ÿá ÿ®ÿßŸÑŸáŸàŸäÿ©
        await client.db("AAIO-Memory").collection("chat_history").insertOne({
            sessionId: sessionId,
            advisor: "DeepSeek",
            userName: "User",
            userPrompt: prompt,
            botReply: reply,
            timestamp: new Date()
        });

        res.json({ reply });
    } catch (error) {
        console.error("‚ùå DeepSeek Error:", error.message);
        res.status(500).json({ error: "DeepSeek Service Unavailable" });
    }
});

// --- Claude Advisor ---
router.post('/ask-claude', async (req, res) => {
    // 1. ÿßÿ≥ÿ™ŸÑÿßŸÖ ÿßŸÑŸáŸàŸäÿ© ŸàÿßŸÑÿ≥ÿ§ÿßŸÑ ŸÖŸÜ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠
    const { prompt, sessionId } = req.body;
    try {
        // 2. ÿ¨ŸÑÿ® ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ¨ŸÑÿ≥ÿ© ÿßŸÑŸÖŸÅŸÑÿ™ÿ±
        const historyText = await getRecentHistory(sessionId);
        
        // ÿ£ÿ∂ŸÅŸÜÿß ÿ™ŸÜÿ®ŸäŸáÿßŸã ÿµÿßÿ±ŸÖÿßŸã ŸáŸÜÿß ŸÑÿ£ŸÜ ŸÉŸÑÿßŸàÿØ ŸäŸÖŸäŸÑ ÿ£ÿ≠ŸäÿßŸÜÿßŸã ŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿ™ÿØÿ±Ÿäÿ®Ÿá ÿßŸÑÿ≥ÿßÿ®ŸÇ
        const finalPrompt = `
${UNIFIED_PROMPT}
---
Council History:
${historyText}
---
User Query: ${prompt}
Note: You MUST respond in the exact same language used in the User Query above. This is a technical requirement for the AAIO project.
`;

        const response = await axios.post('https://api.anthropic.com/v1/messages', {
            model: "claude-3-haiku-20240307",
            max_tokens: 1024,
            system: UNIFIED_PROMPT, // ÿßŸÑÿØÿ≥ÿ™Ÿàÿ± ÿßŸÑŸÖŸàÿ≠ÿØ Ÿäÿ±ÿ≥ŸÑ ŸáŸÜÿß ŸÉŸÖÿ§ÿ¥ÿ± ŸÜÿ∏ÿßŸÖ
            messages: [{ role: "user", content: finalPrompt }]
        }, {
            headers: {
                'x-api-key': process.env.CLAUDE_API_KEY,
                'anthropic-version': '2023-06-01',
                'content-type': 'application/json'
            }
        });

        const reply = response.data.content[0].text;

        // 3. ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑÿ±ÿØ ŸÖÿπ ÿßŸÑŸáŸàŸäÿ© ŸÑÿ∂ŸÖÿßŸÜ ÿπÿØŸÖ ÿ™ÿØÿßÿÆŸÑ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©
        await client.db("AAIO-Memory").collection("chat_history").insertOne({
            sessionId: sessionId,
            advisor: "Claude",
            userName: "User",
            userPrompt: prompt,
            botReply: reply,
            timestamp: new Date()
        });

        res.json({ reply });
    } catch (error) {
        console.error("‚ùå Claude Error:", error.response?.data || error.message);
        res.status(500).json({ error: "Claude Service Unavailable" });
    }
});

// --- Llama 3.1 Advisor (via Groq) ---
router.post('/ask-llama', async (req, res) => {
    const { prompt, sessionId } = req.body;
    try {
        const historyText = await getRecentHistory(sessionId);
        const finalPrompt = `
${UNIFIED_PROMPT}
---
Council History:
${historyText}
---
User Query: ${prompt}
Note: Respond in the same language as the User Query.
`;

        const response = await axios.post('https://api.groq.com/openai/v1/chat/completions', {
            model: "llama-3.3-70b-versatile",
            messages: [
                { role: "system", content: UNIFIED_PROMPT },
                { role: "user", content: finalPrompt }
            ]
        }, {
            headers: { 'Authorization': `Bearer ${process.env.GROQ_API_KEY}` }
        });

        const reply = response.data.choices[0].message.content;
        await client.db("AAIO-Memory").collection("chat_history").insertOne({
            sessionId, advisor: "Llama", userPrompt: prompt, botReply: reply, timestamp: new Date()
        });
        res.json({ reply });
    } catch (error) {
        console.error("‚ùå Llama Error:", error.message);
        res.status(500).json({ error: "Llama Service Unavailable" });
    }
});

// --- Mistral Large Advisor ---
router.post('/ask-mistral', async (req, res) => {
    const { prompt, sessionId } = req.body;
    try {
        const historyText = await getRecentHistory(sessionId);
        const finalPrompt = `
${UNIFIED_PROMPT}
---
Council History:
${historyText}
---
User Query: ${prompt}
Note: Respond in the same language as the User Query.
`;

        const response = await axios.post('https://api.mistral.ai/v1/chat/completions', {
            model: "mistral-large-latest",
            messages: [
                { role: "system", content: UNIFIED_PROMPT },
                { role: "user", content: finalPrompt }
            ]
        }, {
            headers: { 'Authorization': `Bearer ${process.env.MISTRAL_API_KEY}` }
        });

        const reply = response.data.choices[0].message.content;
        await client.db("AAIO-Memory").collection("chat_history").insertOne({
            sessionId, advisor: "Mistral", userPrompt: prompt, botReply: reply, timestamp: new Date()
        });
        res.json({ reply });
    } catch (error) {
        console.error("‚ùå Mistral Error:", error.message);
        res.status(500).json({ error: "Mistral Service Unavailable" });
    }
});
return router;
};